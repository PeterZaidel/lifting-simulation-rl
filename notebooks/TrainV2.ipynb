{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "import argparse\n",
    "from ddpg_torch.ddpg_torch import Agent\n",
    "import gym\n",
    "import numpy as np\n",
    "from lifting_rl.linkage_env_2 import LinkageEnvV2\n",
    "from lifting_rl.ddpg.utils import OUNoise, NormalizedEnv, Memory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "guilty-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"N_LINKS\": 1,\n",
    "#     \"INIT_STATE\": np.array([np.pi / 4, 0], dtype=np.float32),\n",
    "#     \"PARAM_VALS\": np.array([9.81, 0.4, 1], dtype=np.float32),\n",
    "#     \"OBS_LOW\": np.array([-np.pi, -8 * np.pi], dtype=np.float32),\n",
    "#     \"OBS_HIGH\": np.array(\n",
    "#         [np.pi, 8 * np.pi], dtype=np.float32\n",
    "#     ),\n",
    "#     \"ACT_LOW\": -10,\n",
    "#     \"ACT_HIGH\": 10,\n",
    "#     \"TIME_STEP\": 0.01,\n",
    "#     \"VIDEO_FPS\": 30,\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    \"N_LINKS\": 5,\n",
    "    \"INIT_STATE\": np.array([np.pi / 2, np.pi/2, np.pi/2, -np.pi/4, np.pi/4, 0, 0, 0, 0, 0], dtype=np.float32),\n",
    "    \"PARAM_VALS\": np.array([9.81, 0.4, 1, 0.4, 1, 0.6, 1, 0.4, 1, 0.4, 1]),\n",
    "    \"OBS_LOW\": np.array([0, np.pi/4, -np.pi/2, -np.pi, -np.pi, -8, -8, -8, -8, -8], dtype=np.float32),\n",
    "    \"OBS_HIGH\": np.array(\n",
    "        [3*np.pi/4, 3*np.pi/2, 3*np.pi/4, np.pi/2, np.pi, 8, 8, 8, 8, 8], dtype=np.float32\n",
    "    ),\n",
    "    \"ACT_LOW\": -100,\n",
    "    \"ACT_HIGH\": 100,\n",
    "    \"TIME_STEP\": 0.01,\n",
    "    \"VIDEO_FPS\": 30,\n",
    "}\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     \"N_LINKS\": 5,\n",
    "#     \"INIT_STATE\": np.array([1.4993862, 1.6887208, 1.5188664, -1.4618884, -1.2326124, 0, 0, 0, 0, 0], dtype=np.float32),\n",
    "#     \"PARAM_VALS\": np.array([\n",
    "#         9.81, \n",
    "#         0.4, 5,\n",
    "#         0.4, 8,\n",
    "#         0.6, 45, \n",
    "#         0.4, 6, \n",
    "#         0.4, 5\n",
    "#     ]),\n",
    "#     \"OBS_LOW\": np.array([0, np.pi/4, -np.pi/2, -np.pi, -np.pi, -8, -8, -8, -8, -8], dtype=np.float32),\n",
    "#     \"OBS_HIGH\": np.array(\n",
    "#         [3*np.pi/4, 3*np.pi/2, 3*np.pi/4, np.pi/2, np.pi, 8, 8, 8, 8, 8], dtype=np.float32\n",
    "#     ),\n",
    "#     \"ACT_LOW\": -10,\n",
    "#     \"ACT_HIGH\": 10,\n",
    "#     \"TIME_STEP\": 0.01,\n",
    "#     \"VIDEO_FPS\": 30,\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_file = \"../data/skeleton_angles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brief-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_space:  Box(-8.0, 8.0, (10,), float32)\n",
      "action_space:  Box(-100.0, 100.0, (5,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = LinkageEnvV2(angles_file, params,verbose=0, use_scipy_integration=True) #gym.make(\"Pendulum-v0\") #LinkageEnvV2(angles_file, params, target_pos=np.array([np.pi / 2]) ,verbose=0) #NormalizedEnv( gym.make(\"Pendulum-v0\") )#LinkageEnv(angles_file, params, verbose=0)\n",
    "env = NormalizedEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authentic-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('env_5link_simplified.pkl', 'wb') as f:\n",
    "#     pickle.dump(env, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intense-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-100.0, 100.0, (5,), float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "backed-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "micro-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    lr_actor=0.001,\n",
    "    lr_critic=0.001,\n",
    "    input_dims=[num_states],\n",
    "    tau=0.001,\n",
    "    env=env,\n",
    "    batch_size=128,\n",
    "    layer1_size=400,\n",
    "    layer2_size=400,\n",
    "    n_actions=num_actions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "changed-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "preliminary-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "liveloss = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increased-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-violation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/miniconda3/envs/rl_env/lib/python3.7/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#liveloss = PlotLosses()\n",
    "#score_history = []\n",
    "\n",
    "for i in range(100000):\n",
    "    done = False\n",
    "    score = 0\n",
    "    obs = env.reset()\n",
    "    agent.noise.reset()\n",
    "    \n",
    "    data_q = []\n",
    "    data_dq = []\n",
    "    data_tq = []\n",
    "    data_rewards = []\n",
    "    data_actions = []\n",
    "    \n",
    "    for step in range(500):\n",
    "#         if i % 20 == 0:\n",
    "        env.render()\n",
    "        act = agent.choose_action(obs)\n",
    "        new_state, reward, done, info = env.step(act)\n",
    "        agent.remember(obs, act, reward, new_state, int(done))\n",
    "        agent.learn()\n",
    "        score += reward\n",
    "        obs = new_state\n",
    "        \n",
    "        #cur_target = env.get_cur_target_pos()\n",
    "        s = env.state\n",
    "        data_q.append(s[0])\n",
    "        data_dq.append(s[1])\n",
    "        #data_tq.append(cur_target[0])\n",
    "        data_rewards.append(reward)\n",
    "        data_actions.append(act[0])\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        clear_output()\n",
    "\n",
    "        plt.plot(data_q)\n",
    "        plt.plot(data_dq)\n",
    "    #     plt.plot(data_tq)\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(data_rewards)\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(data_actions)\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "    \n",
    "    score_history.append(score)\n",
    "    metrics = {\n",
    "        \"score_history\": np.mean(score_history[-100:]),\n",
    "        \"score\": score\n",
    "    }\n",
    "    liveloss.update(metrics)\n",
    "    liveloss.send()\n",
    "    print(\n",
    "        \"episode\",\n",
    "        i,\n",
    "        \"score %.2f\" % score,\n",
    "        \"100 game average %.2f\" % np.mean(score_history[-100:]),\n",
    "    )\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "thermal-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "improving-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2541198.473531222, -272322.8299392415]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_history[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "global-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "9 * np.pi / 4 % (2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-japanese",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
